{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efd1a19",
   "metadata": {},
   "source": [
    "# Uncovering Structure in Data\n",
    "\n",
    "Data can be hard to understand sometimes. We can picture it in 2 dimensions, and maybe 3 dimensions, if we use graphs. But what about in higher dimensions? In this case we might want to view our data in a lower dimension without losing too much information. Or, we want to uncover structure that we suspect might be there. In this case, the structure might be smaller groupings of the data where similar observations are grouped together.\n",
    "\n",
    "In this lesson we'll cover two approaches that can help us better understand our data by uncovering structure. These two methods are:\n",
    "1. Hierarchical Clustering (HCL)\n",
    "    * Given observation described by features, it is common to want similar features to be grouped together.\n",
    "    * Sometimes we have an idea of what the structure should be, but we don't always know how to get there. HCL doesn't require us to specify what the structure is beforehand.\n",
    "2. Principal Component Analysis (PCA)\n",
    "    * Finds a low-dimensional representation that can allow us to view the data and observe structure\n",
    "    * Balances low-dimensional representation without losing too much information\n",
    "    \n",
    "## Features\n",
    "What do I mean when I talk about observation being described by features? Here, I mean that an observation is represented by a list (or an array/vector in other terms) of numbers.\n",
    "\n",
    "### Note\n",
    "Many of my images will be drawn from this [book](https://people.unica.it/claudioconversano/files/2015/02/ISLR_print4.pdf). I highly recommend reading it if you're interested in more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6616c",
   "metadata": {},
   "source": [
    "## Libraries Needed\n",
    "Please run this code as soon as you can. Any issues here are usually just install issues, and though annoying can take time to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ade3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from sklearn import decomposition\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af881147",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_observation = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af70cf2",
   "metadata": {},
   "source": [
    "The above example is an observation with 6 features, ie 6 dimensions.\n",
    "\n",
    "If we stack these observations on top of each other we'd have a list of lists, or a matrix, where each observation is represented by a row, and each row has 6 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20607bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_observation_1 = \n",
    "example_observation_2 = \n",
    "stacked_observations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacked_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_observations = np.array(stacked_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3010322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix_observations)\n",
    "print(\"The shape of our matrix is\", matrix_observations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44754759",
   "metadata": {},
   "source": [
    "But what do these features mean? Well, that depends on our data.\n",
    "\n",
    "1. Text data\n",
    "    * Each observation could be a document.\n",
    "    * Each element in our feature list for a document might be a whole number, representing he number of times a word appears in that document.\n",
    "2. Disease codes\n",
    "    * Each observation is a patient.\n",
    "    * Each element in our feature list might be the presence of a disease code, the value for a labratory test, a vital sign value, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a73fbe",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "Hierarchical clustering is an appraoch the builds an upside down tree of relationships between observations. This is known as a dendrogram.\n",
    "\n",
    "That's a little bit confusing. Sometimes an example can help!\n",
    "Below is an example of 2 dimensional data in a flat representation. What might this look like as a dendrogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117763b",
   "metadata": {},
   "source": [
    "<img src=\"img/example_2d_data.png\" alt=\"flat_2d_cluster\" style=\"width: 500px;\"/>\n",
    "An example of data points in a flat clustering representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d1bd3",
   "metadata": {},
   "source": [
    "<img src=\"img/dendrogram_1.png\" alt=\"dendrogram_no_cut\" style=\"width: 500px;\"/>\n",
    "The flat data represented as a dendrogram. Notice that there aren't  any clusters just yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e41d5",
   "metadata": {},
   "source": [
    "So, how do we interpret this dendrogram?\n",
    "* The observations along the bottom are known as leaves. \n",
    "* As we move up, we begin to fuse leaves. These are known as subgroups or clusters.\n",
    "* The earlier these fusions happen the more similar those observations are than leaves which were fused later.\n",
    "    * Be careful with spatial interpretations. Height matters, but distance along the x axis does not. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c7f81",
   "metadata": {},
   "source": [
    "<img src=\"img/dendrogram_cuts_cropped.png\" alt=\"dendrogram_cut\" style=\"width: 2000px;height: 400px;\"/>\n",
    "By choosing the point on a point on the y axis we can choose what clusters we wantto create\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62daa352",
   "metadata": {},
   "source": [
    "One thing you might notice is that there aren't any clusters even though we've induced some kind of structure. In order to identify clusters from the structure we need to choose where to \"cut\" along the y axis.\n",
    "\n",
    "The y axis represents how close observations are, as in the lower on the y axis leaves are fused the more similar they are.\n",
    "\n",
    "Next you might ask how do we measure how similar or close leaves are? How does that apply to groups of leaves?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b1267",
   "metadata": {},
   "source": [
    "### Measures of distance\n",
    "Recall that we're working with observation that are represented as lists of numbers. We can measure how close or similar these observations are to one another using these features.\n",
    "\n",
    "Many distance measurs exist. Examples include:\n",
    "* Euclidean distance\n",
    "    * A measure which looks at the distance between each corresponding feature in two lists of features.\n",
    "    * d(p,q) = $\\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2}$\n",
    "    * A standard measure that is used, but can weigh certain features more than others if they are big.\n",
    "* Cosine distance\n",
    "    * Measures the cosine of an angle between two lists of features\n",
    "    * Usually a safe measure, unless you care about how \"big\" feature lists are.\n",
    "    * Technically the distance is 1 - cos(angle between lists of features)\n",
    "* Jaccard distance\n",
    "    * A measure for looking at set similarities. Perfect for binary lists.\n",
    "    * Only works if you're looking at sets, ie an object is in a set or it's not.\n",
    "    * Technically the distance is 1 - jaccard similarity.\n",
    "    \n",
    "Overall, the distance measure matters a great deal for HCL, and in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8a496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edecb285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7286bd2d",
   "metadata": {},
   "source": [
    "### Exercise: Calculate the distance between the two points using two three different distance measures\n",
    "[pdist](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html#scipy.spatial.distance.pdist) is a good function to calculate distances. Look at the documentation and see how you might use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77936a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e434442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c3305f1",
   "metadata": {},
   "source": [
    "### Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa4a0c",
   "metadata": {},
   "source": [
    "1. Begin with all $n$ observations and a distance/dissimilarity measure. \n",
    "2. Measure the distance between all observations, treating each observation as its own cluster.\n",
    "3. For $i = n, n-1, n-2, ... 2$:\n",
    "    * (a) Examine all the inter-cluster distances among the $i$ clusters. Fuse the two clusters that are most similar. The distance between these two clusters indicates the height (yaxis) in the dendrogram to place this merge. \n",
    "    * (b) Compute the new pairwise distance among the remaining clusters (including the fused cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a644e05",
   "metadata": {},
   "source": [
    "## How do we measure the distance between clusters?\n",
    "Measuring the distance when each \"cluster\" has only one observation is fairly intuitive. But when these clusters contain multiple observations we have to get a little fancy. Here are examples of how to measure the distance between clusters.\n",
    "\n",
    "* Complete (maximum distance)\n",
    "    * Computer all pairwise distances between the observation in two clusters and take the *largest* distance.\n",
    "* Single (minimum distance)\n",
    "    * Computer all pairwise distances between the observation in two clusters and take the *smallest* distance.\n",
    "* Average\n",
    "    * Computer all pairwise distances between the observation in two clusters and take the *average* distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0977b00",
   "metadata": {},
   "source": [
    "### Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf94885",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c4bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"data/All_taxa.csv\"\n",
    "# data_path = \"data/Fungi.csv\"\n",
    "# data_path = \"data/Bacteria.csv\"\n",
    "# data_path = \"data/Protist.csv\"\n",
    "# data_path = \"data/Archaea.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e927576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a785f533",
   "metadata": {},
   "source": [
    "## Exercise: Experiment with different distance metrics and cluster distance metrics\n",
    "\n",
    "Try some different distance metrics and cluster distance metrics. Look at the documentation for [scipy.cluster.hierarchy.linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html) to see how you can change these arguments. Try reading in different sample data and seeing how the dendrogram changes. **Do you need to perform any transformations on the data we did before?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89df800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ddaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8106c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e48db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c42b674b",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "Recall that we needed clustering in the first place because there are times when our data is in too high of a dimension for us to visualize it. Even though we wanted to uncover structure, or confirm structure which should be there, we couldn't without HCL. \n",
    "\n",
    "\n",
    "1. Principal Component Analysis (PCA) can allow us to reduce dimensions down to two or three which allows us to visualize it easier.\n",
    "2. Even if we don't want to visualize the data in lower dimensions, we might want to represent observations with their most important features.\n",
    "3. PCA allows us to reduce dimensionality while maintaining the underlying structure of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592da3cb",
   "metadata": {},
   "source": [
    "### What is PCA?\n",
    "I'm going to do a lot of handwaving here,  but PCA is essentially a method to find a low-dimensional representation that conatins as much variation from the original data as possible.\n",
    "\n",
    "What do we mean by variation? Basically, some dimensions of the data are not as \"interesting\" as others, where interesting is a measure for how much the observations vary along this dimension. Note that these dimensions are not the original dimensions of the data and are new ones.\n",
    "\n",
    "Let's interpret this toy example. [source](https://towardsdatascience.com/principal-components-analysis-explained-53f0639b2781)\n",
    "\n",
    "<img src=\"img/PCA_example.png\" alt=\"PCA_interp\" style=\"width: 2000px;height: 400px;\"/>\n",
    "\n",
    "\n",
    "Generally speaking, it's difficult to interpret these directions and is subjective. Once we perform this transformation on the data, the individual features lose their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df385db",
   "metadata": {},
   "source": [
    "### Coding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/All_taxa.csv\"\n",
    "# data_path = \"data/Fungi.csv\"\n",
    "# data_path = \"data/Bacteria.csv\"\n",
    "# data_path = \"data/Protist.csv\"\n",
    "# data_path = \"data/Archaea.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624dcf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dimensional PCA decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e36483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 dimensional PCA decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f3a80",
   "metadata": {},
   "source": [
    "### Exercise: Edit some of the plot parameters\n",
    "This is more of an exercise in presentation. Can you "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d5a54",
   "metadata": {},
   "source": [
    "## Accuracy vs Precision\n",
    "Let's say that we have a quantity that we're trying to measure. Here, the quantity is some measurable phenomenon like the temperature of a glass of water or oxygen content in a patient's blood. We have repeated measuremens of this quantity. Following the previous examples this might be thermometers in the water, or a pulse oximeter. We can define two measurements of good observations.\n",
    "1. Accuracy\n",
    "    * Measures the difference between the average of our observations and the true value of the random variable being measured.\n",
    "    * Accuracy tells us about systematic errors, or errors that come from our ability to measure the quantity well (Imagine a broken thermometer)\n",
    "    * To measure accuracy we would need a reference value. If we knew the true value of the quantity we were tryingto measure we wouldn't be measuring it. A reference value allows us to calibrate the measurement tools.\n",
    "2. Precision\n",
    "    * Measures how close the observations are to each other.\n",
    "    * Precision tells us about random errors, orthe variability of the quantity being measured.\n",
    "    \n",
    "All in all, we can think of accuracy as telling us how far away our measurements are from the true value, and precision as the spread or variability of our data. These two values tell us how good our measurements are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851aadc",
   "metadata": {},
   "source": [
    "### Coding Example\n",
    "Let's say we want to measure a quantity that is centered around the value 5. Let's draw some measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a52c5",
   "metadata": {},
   "source": [
    "### Small example where things go well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d9e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3445095",
   "metadata": {},
   "source": [
    "### Small example where precision is bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4c9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb7f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8064659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaecbeab",
   "metadata": {},
   "source": [
    "### Small example where accuracy is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdd026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569706b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af53f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00234029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "596387c7",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "One issue we might run into is randomness or noise in our data. This is a normal occurence in data collection, even with the most strict and best tools. Noise impacts our analysis by questioning whether we can trust our clusters. Maybe we got a few observations that make it look like there is structure when there really isn't. So how can we address this?\n",
    "\n",
    "One way to address noise in your analysis is to use bootstrapping. Bootstrapping is a resampling technique that mimicks the original sampling process and allowing us to generate multiple datasets from the original dataset. In our case, this allows us to generate multiple clusters to assess stability of our cluster assignments.\n",
    "\n",
    "Bootstrapping works by \n",
    "1. Sample with replacement n observations from a dataset of size n\n",
    "2. Calculate your statistic of interest (clustering assignments, mean, variance, etc)\n",
    "3. Repeat h times. h is usually a large number like 500 or 1000 in my experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(loc = 5, scale = 3, size = 10)\n",
    "X[0] = 20\n",
    "X[1] = 15\n",
    "print(\"\\nMean: {}\".format(np.mean(X)))\n",
    "print(\"\\nStandard deviation: {}\".format(np.std(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f590f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d50651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bootstrap means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38f445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
